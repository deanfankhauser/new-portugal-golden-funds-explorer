name: Complete Production to Development Sync

on:
  workflow_dispatch:
    inputs:
      confirm:
        description: 'Type "SYNC_ALL" to proceed with complete database sync (this will overwrite development data)'
        required: true
        default: ''

jobs:
  complete-sync:
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.confirm == 'SYNC_ALL' }}
    
    env:
      PROD_DB_URL: ""
      DEV_DB_URL: ""
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: latest

      - name: Install PostgreSQL 17 client
        run: |
          sudo apt-get update
          sudo apt-get install -y wget ca-certificates
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" | sudo tee /etc/apt/sources.list.d/pgdg.list
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17 dnsutils curl jq
          echo "/usr/lib/postgresql/17/bin" >> $GITHUB_PATH
          export PATH="/usr/lib/postgresql/17/bin:$PATH"
          pg_dump --version
          psql --version

      - name: Configure database URLs
        run: |
          echo "Configuring database URLs..."
          if [ -n "${{ secrets.PROD_DB_POOLER_URL }}" ] && [ -n "${{ secrets.DEVELOP_DB_POOLER_URL }}" ]; then
            echo "✅ Using pooler URLs"
            echo "PROD_DB_URL=${{ secrets.PROD_DB_POOLER_URL }}" >> $GITHUB_ENV
            echo "DEV_DB_URL=${{ secrets.DEVELOP_DB_POOLER_URL }}" >> $GITHUB_ENV
          else
            echo "⚠️  Using standard database URLs"
            echo "PROD_DB_URL=${{ secrets.PROD_SUPABASE_DB_URL }}" >> $GITHUB_ENV
            echo "DEV_DB_URL=${{ secrets.DEVELOP_SUPABASE_DB_URL }}" >> $GITHUB_ENV
          fi

      - name: Normalize database URLs
        run: |
          normalize() {
            local url="$1"
            if [[ "$url" != postgresql://* && "$url" != postgres://* ]]; then
              echo "ERROR: Invalid connection string" >&2
              exit 1
            fi
            if [[ "$url" == *\?* ]]; then
              if [[ "$url" != *sslmode=* ]]; then
                echo "${url}&sslmode=require"
              else
                echo "$url"
              fi
            else
              echo "${url}?sslmode=require"
            fi
          }
          PROD_DB_URL_NORM=$(normalize "${PROD_DB_URL}")
          DEV_DB_URL_NORM=$(normalize "${DEV_DB_URL}")
          echo "PROD_DB_URL_NORM=${PROD_DB_URL_NORM}" >> $GITHUB_ENV
          echo "DEV_DB_URL_NORM=${DEV_DB_URL_NORM}" >> $GITHUB_ENV

      - name: Create temp directory
        run: |
          mkdir -p /tmp/complete-sync
          cd /tmp/complete-sync

      - name: Dump complete production database schema and data
        run: |
          echo "🔄 Dumping complete production database..."
          cd /tmp/complete-sync
          
          # Complete dump including schema, data, functions, triggers
          echo "Creating complete database dump..."
          pg_dump \
            --verbose \
            --no-owner \
            --no-privileges \
            --format=plain \
            --dbname="${PROD_DB_URL_NORM}" \
            > complete_production_dump.sql
          
          echo "✅ Complete production dump created"
          echo "Dump file size: $(du -h complete_production_dump.sql | cut -f1)"

      - name: Extract and prepare schema components
        run: |
          echo "🔄 Extracting schema components..."
          cd /tmp/complete-sync
          
          # Create SQL script to recreate everything in correct order
          cat > sync_schema.sql << 'EOF'
          -- ==================================================
          -- COMPLETE SCHEMA AND DATA SYNC SCRIPT
          -- ==================================================
          
          -- 1. Drop existing objects in correct order
          DROP SCHEMA IF EXISTS public CASCADE;
          CREATE SCHEMA public;
          GRANT ALL ON SCHEMA public TO postgres;
          GRANT ALL ON SCHEMA public TO public;
          
          -- 2. Set search path
          SET search_path = public;
          
          EOF
          
          # Append the complete dump
          cat complete_production_dump.sql >> sync_schema.sql
          
          echo "✅ Schema sync script prepared"

      - name: Sync Supabase auth and storage via API
        run: |
          echo "🔄 Syncing auth and storage via Supabase API..."
          cd /tmp/complete-sync
          
          # Set up environment variables for API calls
          PROD_URL="${{ secrets.SUPABASE_URL }}"
          PROD_SERVICE_KEY="${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}"
          DEV_URL="${{ secrets.FUNDS_DEV_SUPABASE_URL }}"
          DEV_SERVICE_KEY="${{ secrets.FUNDS_DEV_SUPABASE_SERVICE_ROLE_KEY }}"
          
          echo "Syncing storage buckets and policies..."
          
          # Get storage buckets from production
          curl -s -H "Authorization: Bearer ${PROD_SERVICE_KEY}" \
               -H "apikey: ${PROD_SERVICE_KEY}" \
               "${PROD_URL}/storage/v1/bucket" > prod_buckets.json
          
          echo "Production buckets:"
          cat prod_buckets.json | jq '.'
          
          # Create buckets in development
          while IFS= read -r bucket; do
            BUCKET_ID=$(echo "$bucket" | jq -r '.id')
            BUCKET_NAME=$(echo "$bucket" | jq -r '.name')
            IS_PUBLIC=$(echo "$bucket" | jq -r '.public')
            
            echo "Creating bucket: $BUCKET_ID (public: $IS_PUBLIC)"
            
            curl -s -X POST \
                 -H "Authorization: Bearer ${DEV_SERVICE_KEY}" \
                 -H "apikey: ${DEV_SERVICE_KEY}" \
                 -H "Content-Type: application/json" \
                 -d "{\"id\": \"$BUCKET_ID\", \"name\": \"$BUCKET_NAME\", \"public\": $IS_PUBLIC}" \
                 "${DEV_URL}/storage/v1/bucket" || echo "Bucket may already exist"
          done < <(cat prod_buckets.json | jq -c '.[]')

      - name: Apply complete schema and data sync
        run: |
          echo "🔄 Applying complete schema and data sync..."
          cd /tmp/complete-sync
          
          echo "Applying schema sync script..."
          psql "${DEV_DB_URL_NORM}" < sync_schema.sql
          
          echo "✅ Schema and data sync completed"

      - name: Sync storage policies via SQL
        run: |
          echo "🔄 Syncing storage policies..."
          cd /tmp/complete-sync
          
          cat > storage_policies.sql << 'EOF'
          -- ===============================================
          -- STORAGE POLICIES SYNC
          -- ===============================================
          
          -- Enable RLS on storage.objects
          ALTER TABLE storage.objects ENABLE ROW LEVEL SECURITY;
          
          -- Drop existing policies
          DROP POLICY IF EXISTS "Public read fund logos" ON storage.objects;
          DROP POLICY IF EXISTS "Public read profile photos" ON storage.objects;
          DROP POLICY IF EXISTS "Users can view own pending fund briefs" ON storage.objects;
          DROP POLICY IF EXISTS "Users can upload own pending fund briefs" ON storage.objects;
          DROP POLICY IF EXISTS "Admins can view pending fund briefs" ON storage.objects;
          DROP POLICY IF EXISTS "Admins can modify pending fund briefs" ON storage.objects;
          DROP POLICY IF EXISTS "Users can view own fund briefs" ON storage.objects;
          DROP POLICY IF EXISTS "Admins can view all fund briefs" ON storage.objects;
          DROP POLICY IF EXISTS "Admins can modify fund briefs" ON storage.objects;
          DROP POLICY IF EXISTS "Users can upload profile photos" ON storage.objects;
          DROP POLICY IF EXISTS "Users can update profile photos" ON storage.objects;
          DROP POLICY IF EXISTS "Admins can upload fund logos" ON storage.objects;
          DROP POLICY IF EXISTS "Admins can update fund logos" ON storage.objects;
          
          -- Create all storage policies
          CREATE POLICY "Public read fund logos"
          ON storage.objects FOR SELECT
          USING (bucket_id = 'fund-logos');

          CREATE POLICY "Public read profile photos"
          ON storage.objects FOR SELECT
          USING (bucket_id = 'profile-photos');

          CREATE POLICY "Users can view own pending fund briefs"
          ON storage.objects FOR SELECT
          USING (
            bucket_id = 'fund-briefs-pending'
            AND auth.uid()::text = (storage.foldername(name))[1]
          );

          CREATE POLICY "Users can upload own pending fund briefs"
          ON storage.objects FOR INSERT
          WITH CHECK (
            bucket_id = 'fund-briefs-pending'
            AND auth.uid()::text = (storage.foldername(name))[1]
          );

          CREATE POLICY "Admins can view pending fund briefs"
          ON storage.objects FOR SELECT
          USING (bucket_id = 'fund-briefs-pending' AND public.is_user_admin());

          CREATE POLICY "Admins can modify pending fund briefs"
          ON storage.objects FOR UPDATE
          USING (bucket_id = 'fund-briefs-pending' AND public.is_user_admin());

          CREATE POLICY "Users can view own fund briefs"
          ON storage.objects FOR SELECT
          USING (
            bucket_id = 'fund-briefs'
            AND auth.uid()::text = (storage.foldername(name))[1]
          );

          CREATE POLICY "Admins can view all fund briefs"
          ON storage.objects FOR SELECT
          USING (bucket_id = 'fund-briefs' AND public.is_user_admin());

          CREATE POLICY "Admins can modify fund briefs"
          ON storage.objects FOR UPDATE
          USING (bucket_id = 'fund-briefs' AND public.is_user_admin());

          CREATE POLICY "Users can upload profile photos"
          ON storage.objects FOR INSERT
          WITH CHECK (
            bucket_id = 'profile-photos'
            AND auth.uid()::text = (storage.foldername(name))[1]
          );

          CREATE POLICY "Users can update profile photos"
          ON storage.objects FOR UPDATE
          USING (
            bucket_id = 'profile-photos'
            AND auth.uid()::text = (storage.foldername(name))[1]
          );

          CREATE POLICY "Admins can upload fund logos"
          ON storage.objects FOR INSERT
          WITH CHECK (bucket_id = 'fund-logos' AND public.is_user_admin());

          CREATE POLICY "Admins can update fund logos"
          ON storage.objects FOR UPDATE
          USING (bucket_id = 'fund-logos' AND public.is_user_admin());
          EOF
          
          echo "Applying storage policies..."
          psql "${DEV_DB_URL_NORM}" < storage_policies.sql
          
          echo "✅ Storage policies synced"

      - name: Copy storage files
        run: |
          echo "🔄 Copying storage files..."
          cd /tmp/complete-sync
          
          # Use Supabase API to copy files between buckets
          PROD_URL="${{ secrets.SUPABASE_URL }}"
          PROD_SERVICE_KEY="${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}"
          DEV_URL="${{ secrets.FUNDS_DEV_SUPABASE_URL }}"
          DEV_SERVICE_KEY="${{ secrets.FUNDS_DEV_SUPABASE_SERVICE_ROLE_KEY }}"
          
          for bucket in "fund-logos" "profile-photos" "fund-briefs" "fund-briefs-pending"; do
            echo "Copying files from bucket: $bucket"
            
            # List files in production bucket
            curl -s -H "Authorization: Bearer ${PROD_SERVICE_KEY}" \
                 -H "apikey: ${PROD_SERVICE_KEY}" \
                 "${PROD_URL}/storage/v1/object/list/${bucket}" > "${bucket}_files.json"
            
            echo "Found $(cat ${bucket}_files.json | jq '. | length') files in $bucket"
            
            # Copy each file (simplified - just log for now due to complexity)
            echo "Storage file copying would require individual file downloads and uploads"
            echo "This can be implemented based on specific requirements"
          done

      - name: Verify complete sync
        run: |
          echo "🔍 Verifying complete sync..."
          
          echo "=== TABLE COUNTS ==="
          psql "${DEV_DB_URL_NORM}" -c "
            SELECT 
              schemaname, 
              relname as table_name, 
              n_tup_ins + n_tup_upd + n_tup_del as total_rows 
            FROM pg_stat_user_tables 
            WHERE schemaname = 'public' 
            ORDER BY relname;
          "
          
          echo ""
          echo "=== FUNCTIONS ==="
          psql "${DEV_DB_URL_NORM}" -c "
            SELECT routine_name, routine_type 
            FROM information_schema.routines 
            WHERE routine_schema = 'public'
            ORDER BY routine_name;
          "
          
          echo ""
          echo "=== FOREIGN KEYS ==="
          psql "${DEV_DB_URL_NORM}" -c "
            SELECT 
              tc.constraint_name,
              tc.table_name,
              kcu.column_name,
              ccu.table_name AS foreign_table_name,
              ccu.column_name AS foreign_column_name 
            FROM information_schema.table_constraints AS tc 
            JOIN information_schema.key_column_usage AS kcu
              ON tc.constraint_name = kcu.constraint_name
            JOIN information_schema.constraint_column_usage AS ccu
              ON ccu.constraint_name = tc.constraint_name
            WHERE tc.constraint_type = 'FOREIGN KEY' 
              AND tc.table_schema = 'public'
            ORDER BY tc.table_name, tc.constraint_name;
          "
          
          echo ""
          echo "=== RLS POLICIES ==="
          psql "${DEV_DB_URL_NORM}" -c "
            SELECT schemaname, tablename, policyname, cmd 
            FROM pg_policies 
            WHERE schemaname = 'public'
            ORDER BY tablename, policyname;
          "

      - name: Test fund_brief_submissions query
        run: |
          echo "🧪 Testing the problematic query..."
          
          # Test the specific query that was failing
          psql "${DEV_DB_URL_NORM}" -c "
            SELECT COUNT(*) as fund_count FROM public.funds;
            SELECT COUNT(*) as submissions_count FROM public.fund_brief_submissions;
            SELECT COUNT(*) as managers_count FROM public.manager_profiles;
            SELECT COUNT(*) as investors_count FROM public.investor_profiles;
          "
          
          echo "Testing the embed query structure..."
          psql "${DEV_DB_URL_NORM}" -c "
            SELECT 
              fbs.id,
              fbs.fund_id,
              f.name as fund_name,
              mp.manager_name,
              ip.first_name,
              ip.last_name
            FROM public.fund_brief_submissions fbs
            LEFT JOIN public.funds f ON f.id = fbs.fund_id
            LEFT JOIN public.manager_profiles mp ON mp.user_id = fbs.manager_user_id
            LEFT JOIN public.investor_profiles ip ON ip.user_id = fbs.investor_user_id
            LIMIT 5;
          "

      - name: Cleanup
        run: |
          echo "🧹 Cleaning up..."
          rm -rf /tmp/complete-sync
          echo "✅ Cleanup completed"

      - name: Summary
        run: |
          echo "🎉 Complete database sync finished!"
          echo ""
          echo "What was synced:"
          echo "  ✅ Complete database schema (tables, columns, constraints)"
          echo "  ✅ All table data"
          echo "  ✅ Database functions and triggers"
          echo "  ✅ Row Level Security (RLS) policies"
          echo "  ✅ Storage buckets configuration"
          echo "  ✅ Storage policies"
          echo "  ✅ Foreign key relationships"
          echo ""
          echo "The Funds_Develop database should now be fully synchronized"
          echo "with production and the 400 errors should be resolved."